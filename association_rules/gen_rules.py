def _association_rules(left, right, last_item, support, min_confidence, candi_itemsets, helper_itemsets):
    if not left:
        return
    try:
        confidence = support / (candi_itemsets[left] if candi_itemsets[left] else (
            helper_itemsets[left] if helper_itemsets[left] else float("inf")))
    except KeyError as e:
        print(e)
        print(type(candi_itemsets))
        print(type(helper_itemsets))
    if confidence >= min_confidence:
        yield left, right, support, confidence
        for item in left:
            if item > last_item:
                continue  # This ensures same rules aren't visited twice
            yield from _association_rules(
                left - {item}, right | {item},
                item, support, min_confidence, candi_itemsets, helper_itemsets)


def association_rules(candi_itemsets, helper_itemsets, min_confidence, itemset=None):
    """
    Generate association rules ([3] ยง 12.3) from dict of itemsets' supports
    (from :obj:`frequent_itemsets()`). If `itemset` is provided, only generate
    its rules.
    Parameters
    ----------
    itemsets: dict
        A `dict` mapping itemsets to their supports. Can be generated by
        feeding the output of `frequent_itemsets()` to `dict` constructor.
    min_confidence: float
        Confidence percent. Defined as `itemset_support / antecedent_support`.
    itemset: frozenset
        Itemset the association rules of which we are interested in.
    Yields
    ------
    antecedent: frozenset
        The LHS of the association rule.
    consequent: frozenset
        The RHS of the association rule.
    support: int
        The number of instances supporting (containing) this rule.
    confidence: float
        ``total_support / lhs_support``.
    Examples
    --------
    >>> np.random.seed(0)
    >>> N = 100
    >>> X = np.random.random((N, 100)) > .9
    Find all itemsets with at least 5% support:
    >>> itemsets = dict(frequent_itemsets(X, .05))
    >>> len(itemsets)
    116
    Generate all association rules from these itemsets with minimum
    50% confidence:
    >>> rules = association_rules(itemsets, .5)
    >>> rules
    <generator object ...>
    >>> rules = list(rules)
    >>> len(rules)
    7
    >>> rules
    [(frozenset({36}), frozenset({25}), 5, 0.55...),
     (frozenset({63}), frozenset({58}), 5, 0.5),
     ...
     (frozenset({30}), frozenset({32}), 5, 0.55...),
     (frozenset({75}), frozenset({98}), 5, 0.5)]
    Or only the rules for a particular itemset:
    >>> list(association_rules(itemsets, .3, frozenset({75, 98})))
    [(frozenset({75}), frozenset({98}), 5, 0.5),
     (frozenset({98}), frozenset({75}), 5, 0.45...)]
    """
    assert (isinstance(candi_itemsets, dict) and
            isinstance(next(iter(candi_itemsets), frozenset()), frozenset))
    assert 0 < min_confidence <= 1
    from_itemsets = (itemset,) if itemset else sorted(candi_itemsets, key=len, reverse=True)
    for itemset in from_itemsets:
        support = candi_itemsets[itemset]
        for item in itemset:
            right = frozenset({item})
            yield from _association_rules(
                itemset - right, right,
                item, support, min_confidence, candi_itemsets, helper_itemsets)


def rules_stats(rules, itemsets, n_examples):
    """
    Generate additional stats for rules generated by :obj:`association_rules()`.

    Parameters
    ----------
    rules: iterable
        Rules as output by `association_rules()`.
    itemsets: dict
        The itemsets as obtained by `dict(frequent_itemsets(...))`.
    n_examples: int
        The total number of instances (for calculating coverage, lift,
        and leverage).

    Yields
    ------
    atecedent: frozenset
        The LHS of the association rule.
    consequent: frozenset
        The RHS of the association rule.
    support: int
        Support as an absolute number of instances.
    confidence: float
        The confidence percent, calculated as: ``total_support / lhs_rupport``.
    coverage: float
        Calculated as: ``lhs_support / n_examples``
    strength: float
        Calculated as: ``rhs_support / lhs_examples``
    lift: float
        Calculated as: ``n_examples * total_support / lhs_support / rhs_support``
    leverage: float
        Calculated as: ``(total_support * n_examples - lhs_support * rhs_support) / n_examples**2``

    Examples
    --------
    >>> N = 30
    >>> X = np.random.random((N, 50)) > .9
    >>> itemsets = dict(frequent_itemsets(X, .1))
    >>> rules = association_rules(itemsets, .6)
    >>> list(rules_stats(rules, itemsets, N))
    [(frozenset({15}), frozenset({0}), 3, 0.75, 0.13..., 1.5, 3.75, 0.073...),
     (frozenset({47}), frozenset({22}), 3, 0.6, 0.16..., 1.4, 2.57..., 0.061...),
     (frozenset({27}), frozenset({22}), 4, 0.66..., 0.2, 1.16..., 2.85..., 0.086...),
     (frozenset({19}), frozenset({22}), 3, 0.6, 0.16..., 1.4, 2.57..., 0.061...)]

    """
    assert (isinstance(itemsets, dict) and
            isinstance(next(iter(itemsets), frozenset()), frozenset))
    assert n_examples > 0
    for left, right, support, confidence in rules:
        l_support, r_support = itemsets[left], itemsets[right]
        coverage = l_support / n_examples
        strength = (r_support / l_support) if l_support != 0 else None
        lift = (n_examples * confidence / r_support) if r_support != 0 else None
        leverage = ((support * n_examples - l_support * r_support) / n_examples ** 2) if r_support != 0 else None
        yield (left, right, support, confidence,
               coverage, strength, lift, leverage)
